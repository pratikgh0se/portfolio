<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project: CFD Reduction & Observability Enhancement | Pratik Ghose</title>
    <!-- Favicon: A simple cloud icon as SVG -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='%233b82f6'><path d='M19.35 10.04C18.67 6.59 15.64 4 12 4c-3.72 0-6.86 2.53-7.58 6.04C2.71 10.75 1 12.68 1 15c0 3.31 2.69 6 6 6h12c3.31 0 6-2.69 6-6 0-2.68-1.71-4.91-4.65-5.96zM12 6c2.76 0 5 2.24 5 5h-2c0-1.66-1.34-3-3-3s-3 1.34-3 3H7c0-2.76 2.24-5 5-5z'/></svg>" type="image/svg+xml">
    <!-- Link to Font Awesome for icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <!-- Link to Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Link to Google Fonts - Inter -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <!-- Link to external CSS file -->
    <link rel="stylesheet" href="css/style.css">
</head>
<body class="antialiased">
    <!-- Placeholder for Header/Navigation Bar -->
    <div id="header-placeholder"></div>

    <!-- Hero Section -->
    <section class="py-12 md:py-16 bg-gradient-to-br from-green-600 to-emerald-800 text-white">
        <div class="container mx-auto px-4">
            <div class="max-w-6xl mx-auto">
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 items-center">
                    <div>
                        <div class="mb-4">
                            <span class="bg-white bg-opacity-20 text-white px-3 py-1 rounded-full text-sm font-medium">
                                <i class="fas fa-robot mr-2"></i>AI Innovation & Quality Engineering
                            </span>
                        </div>
                        <h1 class="text-4xl md:text-5xl font-bold mb-6 leading-tight">
                            CFD Reduction & AI-Powered Observability Enhancement
                        </h1>
                        <p class="text-xl mb-6 opacity-90 leading-relaxed">
                            Reduced Customer Found Bugs by <span class="text-yellow-300 font-semibold">40%</span> and 
                            cut logging costs by <span class="text-blue-300 font-semibold">38%</span> while pioneering 
                            <span class="text-purple-300 font-semibold">"Pharos" AI-powered RCA system</span>.
                        </p>
                        <div class="flex flex-wrap gap-3 mb-6">
                            <span class="bg-green-500 px-3 py-1 rounded-full text-sm">Grafana</span>
                            <span class="bg-blue-500 px-3 py-1 rounded-full text-sm">Prometheus</span>
                            <span class="bg-purple-500 px-3 py-1 rounded-full text-sm">AI/ML</span>
                            <span class="bg-orange-500 px-3 py-1 rounded-full text-sm">Go</span>
                        </div>
                    </div>
                    
                    <div class="grid grid-cols-2 gap-4">
                        <div class="bg-white bg-opacity-10 backdrop-blur-sm rounded-xl p-4 text-center">
                            <div class="text-2xl font-bold text-green-300">40%</div>
                            <div class="text-sm opacity-90">CFD Reduction</div>
                        </div>
                        <div class="bg-white bg-opacity-10 backdrop-blur-sm rounded-xl p-4 text-center">
                            <div class="text-2xl font-bold text-blue-300">38%</div>
                            <div class="text-sm opacity-90">Cost Savings</div>
                        </div>
                        <div class="bg-white bg-opacity-10 backdrop-blur-sm rounded-xl p-4 text-center">
                            <div class="text-2xl font-bold text-purple-300">30%</div>
                            <div class="text-sm opacity-90">Faster Resolution</div>
                        </div>
                        <div class="bg-white bg-opacity-10 backdrop-blur-sm rounded-xl p-4 text-center">
                            <div class="text-2xl font-bold text-orange-300">AI-Powered</div>
                            <div class="text-sm opacity-90">RCA System</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Project Overview -->
    <section class="py-12 bg-gradient-to-br from-gray-50 to-green-50">
        <div class="container mx-auto px-4">
            <div class="max-w-6xl mx-auto">
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                    <div class="bg-white rounded-xl p-6 shadow-lg border-l-4 border-green-600">
                        <i class="fas fa-building text-green-600 text-2xl mb-3"></i>
                        <h3 class="font-semibold text-gray-800 mb-2">Company</h3>
                        <p class="text-gray-600">ThoughtSpot</p>
                    </div>
                    <div class="bg-white rounded-xl p-6 shadow-lg border-l-4 border-blue-600">
                        <i class="fas fa-calendar text-blue-600 text-2xl mb-3"></i>
                        <h3 class="font-semibold text-gray-800 mb-2">Duration</h3>
                        <p class="text-gray-600">Nov 2021 - April 2024</p>
                    </div>
                    <div class="bg-white rounded-xl p-6 shadow-lg border-l-4 border-purple-600">
                        <i class="fas fa-robot text-purple-600 text-2xl mb-3"></i>
                        <h3 class="font-semibold text-gray-800 mb-2">Innovation</h3>
                        <p class="text-gray-600">AI-powered Root Cause Analysis</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Main Content -->
    <section class="py-16 md:py-20 container mx-auto px-4">
        <div class="max-w-6xl mx-auto">
            
            <!-- Project Summary -->
            <div class="mb-16">
                <div class="bg-white rounded-xl shadow-lg p-8 border-l-4 border-green-600">
                    <h2 class="text-2xl font-bold text-gray-800 mb-6">
                        <i class="fas fa-bug text-green-600 mr-3"></i>Project Overview
                    </h2>
                    <p class="text-lg text-gray-700 leading-relaxed">
                        Spearheaded a comprehensive quality improvement initiative at ThoughtSpot, reducing Customer Found Bugs (CFDs) 
                        by 40% through enhanced proactive monitoring, standardized observability practices, and innovative AI-powered 
                        automation. Simultaneously achieved 38% cost reduction in logging infrastructure while pioneering "Pharos," 
                        an automated Root Cause Analysis system that accelerated incident resolution by 30%.
                    </p>
                </div>
            </div>

            <!-- STAR Method -->
            <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-16">
                
                <!-- Situation & Task -->
                <div class="space-y-8">
                    <div class="bg-white rounded-xl shadow-lg p-8 border-l-4 border-red-600">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">
                            <i class="fas fa-exclamation-triangle text-red-600 mr-3"></i>Situation
                        </h3>
                        <p class="text-gray-700 leading-relaxed">
                            ThoughtSpot was experiencing a high volume of Customer Found Bugs (CFDs), indicating significant gaps 
                            in proactive monitoring and alerting capabilities. This reactive posture led to customer dissatisfaction, 
                            increased support burden, and prolonged MTTR for critical issues. Concurrently, observability costs were 
                            escalating rapidly due to inefficient data retention policies and proliferation of unused logs and metrics.
                        </p>
                    </div>
                    
                    <div class="bg-white rounded-xl shadow-lg p-8 border-l-4 border-blue-600">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">
                            <i class="fas fa-bullseye text-blue-600 mr-3"></i>Task
                        </h3>
                        <p class="text-gray-700 leading-relaxed">
                            The multifaceted task involved: (1) Significantly reducing CFDs by enhancing proactive monitoring and 
                            standardizing observability practices. (2) Optimizing logging and metric costs by identifying and 
                            eliminating redundant data. (3) Designing and building an automated Root Cause Analysis (RCA) tool 
                            to accelerate incident resolution and improve post-incident learning.
                        </p>
                    </div>
                </div>
                
                <!-- Action & Result -->
                <div class="space-y-8">
                    <div class="bg-white rounded-xl shadow-lg p-8 border-l-4 border-orange-600">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">
                            <i class="fas fa-cogs text-orange-600 mr-3"></i>Key Actions
                        </h3>
                        <div class="space-y-3 text-gray-700">
                            <div class="flex items-start">
                                <i class="fas fa-check-circle text-green-600 mt-1 mr-3 flex-shrink-0"></i>
                                <p>Implemented templated Grafana dashboards using RED and USE methodologies</p>
                            </div>
                            <div class="flex items-start">
                                <i class="fas fa-check-circle text-green-600 mt-1 mr-3 flex-shrink-0"></i>
                                <p>Developed Kubernetes CRDs and Operator pattern in Go for automated SLI/SLO management</p>
                            </div>
                            <div class="flex items-start">
                                <i class="fas fa-check-circle text-green-600 mt-1 mr-3 flex-shrink-0"></i>
                                <p>Built "Pharos" AI-powered RCA system with RAG architecture</p>
                            </div>
                            <div class="flex items-start">
                                <i class="fas fa-check-circle text-green-600 mt-1 mr-3 flex-shrink-0"></i>
                                <p>Created Python scripts for metric usage analysis and cost optimization</p>
                            </div>
                        </div>
                    </div>
                    
                    <div class="bg-white rounded-xl shadow-lg p-8 border-l-4 border-green-600">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">
                            <i class="fas fa-trophy text-green-600 mr-3"></i>Results
                        </h3>
                        <div class="grid grid-cols-2 gap-4">
                            <div class="text-center">
                                <div class="text-2xl font-bold text-green-600">40%</div>
                                <div class="text-sm text-gray-600">CFD Reduction</div>
                            </div>
                            <div class="text-center">
                                <div class="text-2xl font-bold text-blue-600">38%</div>
                                <div class="text-sm text-gray-600">Cost Savings</div>
                            </div>
                            <div class="text-center">
                                <div class="text-2xl font-bold text-purple-600">30%</div>
                                <div class="text-sm text-gray-600">Faster Resolution</div>
                            </div>
                            <div class="text-center">
                                <div class="text-2xl font-bold text-orange-600">50%</div>
                                <div class="text-sm text-gray-600">Alert Fatigue Reduction</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- System Architecture -->
            <div class="mb-16">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold text-gray-800 mb-6">
                        <i class="fas fa-sitemap mr-3 text-purple-600"></i>Pharos AI RCA Architecture
                    </h2>
                    <div class="w-24 h-1 bg-purple-600 mx-auto mb-8"></div>
                </div>
                
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
                    <div class="bg-white rounded-xl shadow-lg p-6 border-l-4 border-purple-600">
                        <h4 class="text-lg font-semibold text-gray-800 mb-4">
                            <i class="fas fa-robot text-purple-600 mr-2"></i>RAG-Based AI Architecture
                        </h4>
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <p class="text-gray-700 text-sm italic mb-2">Diagram Placeholder: Pharos AI architecture showing:</p>
                            <ul class="text-gray-600 text-sm space-y-1">
                                <li>• Multi-source data ingestion (Prometheus, Kibana, Slack, Jira)</li>
                                <li>• Vector database for semantic search</li>
                                <li>• LLM integration for context-aware analysis</li>
                                <li>• Automated report generation and Slack integration</li>
                            </ul>
                        </div>
                        <p class="text-gray-700 text-sm">
                            Comprehensive AI-powered system that correlates data across multiple observability 
                            sources to provide intelligent root cause analysis.
                        </p>
                    </div>
                    
                    <div class="bg-white rounded-xl shadow-lg p-6 border-l-4 border-green-600">
                        <h4 class="text-lg font-semibold text-gray-800 mb-4">
                            <i class="fas fa-chart-line text-green-600 mr-2"></i>Proactive Monitoring Flow
                        </h4>
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <p class="text-gray-700 text-sm italic mb-2">Diagram Placeholder: Monitoring workflow showing:</p>
                            <ul class="text-gray-600 text-sm space-y-1">
                                <li>• RED/USE methodology dashboards</li>
                                <li>• Automated SLI/SLO generation via CRDs</li>
                                <li>• Intelligent alerting with context</li>
                                <li>• Cost optimization feedback loop</li>
                            </ul>
                        </div>
                        <p class="text-gray-700 text-sm">
                            Systematic approach to proactive monitoring that prevents issues from reaching customers 
                            while optimizing observability costs.
                        </p>
                    </div>
                </div>
            </div>

            <!-- Technical Implementation -->
            <div class="mb-16">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold text-gray-800 mb-6">
                        <i class="fas fa-code mr-3 text-green-600"></i>Technical Implementation & Code Samples
                    </h2>
                    <div class="w-24 h-1 bg-green-600 mx-auto mb-8"></div>
                </div>
                
                <h4 class="text-lg font-semibold text-gray-800 mb-2">Pharos AI RCA System (Python RAG Implementation)</h4>
                <div class="bg-gray-900 text-green-400 p-4 rounded-lg mb-4 text-sm font-mono overflow-x-auto">
                    <pre><code># Python implementation of Pharos AI-powered Root Cause Analysis
import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import numpy as np
from dataclasses import dataclass
import openai
import chromadb
from prometheus_api_client import PrometheusConnect
import requests
from slack_sdk import WebClient

@dataclass
class IncidentContext:
    incident_id: str
    title: str
    description: str
    severity: str
    start_time: datetime
    affected_services: List[str]
    symptoms: List[str]
    customer_reports: List[str]

@dataclass
class Evidence:
    source: str
    timestamp: datetime
    data_type: str  # 'metric', 'log', 'trace', 'alert'
    content: Dict[str, Any]
    relevance_score: float

class RAGDataCollector:
    def __init__(self, prometheus_url: str, kibana_url: str, jaeger_url: str):
        self.prometheus = PrometheusConnect(url=prometheus_url)
        self.kibana_url = kibana_url
        self.jaeger_url = jaeger_url
        self.logger = logging.getLogger(__name__)
    
    async def collect_metrics_evidence(self, incident: IncidentContext, 
                                     time_window: timedelta) -> List[Evidence]:
        """Collect relevant metrics from Prometheus"""
        evidence = []
        end_time = incident.start_time
        start_time = end_time - time_window
        
        # Define queries for different types of metrics
        metric_queries = {
            'error_rates': [
                'rate(http_requests_total{status=~"5.."}[5m])',
                'increase(application_errors_total[5m])',
                'rate(grpc_server_handled_total{grpc_code!="OK"}[5m])'
            ],
            'latency_metrics': [
                'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))',
                'histogram_quantile(0.99, rate(response_time_seconds_bucket[5m]))',
                'avg(database_query_duration_seconds)'
            ],
            'resource_usage': [
                'rate(container_cpu_usage_seconds_total[5m])',
                'container_memory_usage_bytes',
                'node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes',
                'rate(container_network_receive_bytes_total[5m])'
            ],
            'infrastructure_health': [
                'up',
                'kube_pod_container_status_restarts_total',
                'node_load1',
                'rate(node_disk_io_time_seconds_total[5m])'
            ]
        }
        
        for category, queries in metric_queries.items():
            for query in queries:
                try:
                    # Filter query by affected services if available
                    if incident.affected_services:
                        service_filter = '|'.join(incident.affected_services)
                        if 'service=' not in query:
                            query = query.replace('{', f'{{service=~"{service_filter}",')
                    
                    result = self.prometheus.custom_query_range(
                        query=query,
                        start_time=start_time,
                        end_time=end_time,
                        step="1m"
                    )
                    
                    if result:
                        # Calculate anomaly scores for metrics
                        relevance_score = self._calculate_metric_relevance(
                            result, incident.symptoms
                        )
                        
                        evidence.append(Evidence(
                            source="prometheus",
                            timestamp=end_time,
                            data_type="metric",
                            content={
                                "query": query,
                                "category": category,
                                "values": result,
                                "anomaly_detected": relevance_score > 0.7
                            },
                            relevance_score=relevance_score
                        ))
                
                except Exception as e:
                    self.logger.error(f"Error collecting metric {query}: {e}")
        
        return evidence
    
    async def collect_log_evidence(self, incident: IncidentContext, 
                                 time_window: timedelta) -> List[Evidence]:
        """Collect relevant logs from Kibana/Elasticsearch"""
        evidence = []
        
        # Build Elasticsearch query
        es_query = {
            "size": 100,
            "sort": [{"@timestamp": {"order": "desc"}}],
            "query": {
                "bool": {
                    "must": [
                        {
                            "range": {
                                "@timestamp": {
                                    "gte": (incident.start_time - time_window).isoformat(),
                                    "lte": incident.start_time.isoformat()
                                }
                            }
                        }
                    ],
                    "should": [
                        {"match": {"level": "ERROR"}},
                        {"match": {"level": "WARN"}},
                        {"terms": {"service.name": incident.affected_services}},
                        {"query_string": {
                            "query": " OR ".join([f'"{symptom}"' for symptom in incident.symptoms])
                        }}
                    ],
                    "minimum_should_match": 1
                }
            }
        }
        
        try:
            # Query Elasticsearch through Kibana API
            headers = {
                'Content-Type': 'application/json',
                'kbn-xsrf': 'true'
            }
            
            response = requests.post(
                f"{self.kibana_url}/elasticsearch/_search",
                headers=headers,
                json=es_query,
                timeout=30
            )
            
            if response.status_code == 200:
                results = response.json()
                
                for hit in results.get('hits', {}).get('hits', []):
                    log_entry = hit['_source']
                    
                    relevance_score = self._calculate_log_relevance(
                        log_entry, incident.symptoms, incident.affected_services
                    )
                    
                    evidence.append(Evidence(
                        source="elasticsearch",
                        timestamp=datetime.fromisoformat(
                            log_entry.get('@timestamp', '').replace('Z', '+00:00')
                        ),
                        data_type="log",
                        content=log_entry,
                        relevance_score=relevance_score
                    ))
        
        except Exception as e:
            self.logger.error(f"Error collecting logs: {e}")
        
        return evidence
    
    def _calculate_metric_relevance(self, metric_data: List, symptoms: List[str]) -> float:
        """Calculate relevance score for metric data"""
        if not metric_data:
            return 0.0
        
        relevance_score = 0.0
        
        # Check for anomalies in metric values
        for metric_series in metric_data:
            values = [float(value[1]) for value in metric_series.get('values', [])]
            if len(values) > 1:
                # Simple anomaly detection using standard deviation
                mean_val = np.mean(values)
                std_val = np.std(values)
                
                if std_val > 0:
                    # Check for values outside 2 standard deviations
                    anomalies = [v for v in values if abs(v - mean_val) > 2 * std_val]
                    if anomalies:
                        relevance_score += 0.5
                
                # Check for trend changes
                if len(values) >= 5:
                    recent_avg = np.mean(values[-5:])
                    earlier_avg = np.mean(values[:-5])
                    
                    if abs(recent_avg - earlier_avg) > 0.5 * earlier_avg:
                        relevance_score += 0.3
        
        return min(relevance_score, 1.0)
    
    def _calculate_log_relevance(self, log_entry: Dict, symptoms: List[str], 
                               affected_services: List[str]) -> float:
        """Calculate relevance score for log entries"""
        relevance_score = 0.0
        
        # Check log level
        level = log_entry.get('level', '').upper()
        if level in ['ERROR', 'FATAL']:
            relevance_score += 0.4
        elif level == 'WARN':
            relevance_score += 0.2
        
        # Check service match
        service_name = log_entry.get('service', {}).get('name', '')
        if service_name in affected_services:
            relevance_score += 0.3
        
        # Check symptom keywords in message
        message = log_entry.get('message', '').lower()
        symptom_matches = sum(1 for symptom in symptoms if symptom.lower() in message)
        relevance_score += min(symptom_matches * 0.1, 0.3)
        
        return min(relevance_score, 1.0)

class PharosAIAnalyzer:
    def __init__(self, openai_api_key: str, chroma_db_path: str):
        openai.api_key = openai_api_key
        self.chroma_client = chromadb.PersistentClient(path=chroma_db_path)
        self.knowledge_base = self.chroma_client.get_or_create_collection(
            name="incident_knowledge_base"
        )
        self.logger = logging.getLogger(__name__)
    
    async def analyze_incident(self, incident: IncidentContext, 
                             evidence: List[Evidence]) -> Dict[str, Any]:
        """Perform AI-powered root cause analysis"""
        
        # Sort evidence by relevance
        sorted_evidence = sorted(evidence, key=lambda x: x.relevance_score, reverse=True)
        top_evidence = sorted_evidence[:20]  # Use top 20 most relevant pieces
        
        # Retrieve similar historical incidents
        similar_incidents = await self._find_similar_incidents(incident, top_evidence)
        
        # Generate analysis prompt
        analysis_prompt = self._create_analysis_prompt(incident, top_evidence, similar_incidents)
        
        try:
            # Use GPT-4 for analysis
            response = await openai.ChatCompletion.acreate(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "You are Pharos, an expert SRE AI assistant specialized in root cause analysis for distributed systems. Analyze the provided incident data and evidence to identify the most likely root cause and provide actionable remediation steps."
                    },
                    {
                        "role": "user",
                        "content": analysis_prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.1
            )
            
            analysis_result = response.choices[0].message.content
            
            # Store analysis for future reference
            await self._store_analysis(incident, evidence, analysis_result)
            
            # Structure the response
            structured_analysis = self._parse_analysis_response(analysis_result)
            
            return {
                "incident_id": incident.incident_id,
                "analysis_timestamp": datetime.utcnow().isoformat(),
                "root_cause_analysis": structured_analysis,
                "evidence_count": len(evidence),
                "top_evidence": [
                    {
                        "source": e.source,
                        "type": e.data_type,
                        "relevance": e.relevance_score,
                        "summary": self._summarize_evidence(e)
                    }
                    for e in top_evidence[:5]
                ],
                "similar_incidents": similar_incidents,
                "confidence_score": self._calculate_confidence(top_evidence),
                "recommended_actions": structured_analysis.get("recommendations", [])
            }
            
        except Exception as e:
            self.logger.error(f"Error in AI analysis: {e}")
            return {
                "incident_id": incident.incident_id,
                "error": "Analysis failed",
                "message": str(e)
            }
    
    async def _find_similar_incidents(self, incident: IncidentContext, 
                                    evidence: List[Evidence]) -> List[Dict]:
        """Find similar historical incidents using vector similarity"""
        
        # Create query vector from incident description and symptoms
        query_text = f"{incident.description} {' '.join(incident.symptoms)}"
        
        try:
            # Search for similar incidents in knowledge base
            results = self.knowledge_base.query(
                query_texts=[query_text],
                n_results=5
            )
            
            similar_incidents = []
            for i, (metadata, distance) in enumerate(zip(results['metadatas'][0], results['distances'][0])):
                if distance < 0.8:  # Similarity threshold
                    similar_incidents.append({
                        "incident_id": metadata.get('incident_id'),
                        "title": metadata.get('title'),
                        "resolution": metadata.get('resolution'),
                        "similarity_score": 1 - distance
                    })
            
            return similar_incidents
            
        except Exception as e:
            self.logger.error(f"Error finding similar incidents: {e}")
            return []
    
    def _create_analysis_prompt(self, incident: IncidentContext, 
                              evidence: List[Evidence], 
                              similar_incidents: List[Dict]) -> str:
        """Create structured prompt for AI analysis"""
        
        evidence_summary = "\n".join([
            f"- {e.source} ({e.data_type}): {self._summarize_evidence(e)} (relevance: {e.relevance_score:.2f})"
            for e in evidence[:10]
        ])
        
        similar_cases = "\n".join([
            f"- {case.get('title', 'Unknown')}: {case.get('resolution', 'No resolution available')}"
            for case in similar_incidents
        ])
        
        prompt = f"""
INCIDENT ANALYSIS REQUEST

Incident Details:
- ID: {incident.incident_id}
- Title: {incident.title}
- Description: {incident.description}
- Severity: {incident.severity}
- Start Time: {incident.start_time}
- Affected Services: {', '.join(incident.affected_services)}
- Reported Symptoms: {', '.join(incident.symptoms)}

Evidence Collected:
{evidence_summary}

Similar Historical Incidents:
{similar_cases}

Please provide a comprehensive root cause analysis including:
1. Most likely root cause with confidence level
2. Contributing factors
3. Impact assessment
4. Immediate remediation steps
5. Long-term prevention measures
6. Monitoring recommendations

Format your response as structured sections for easy parsing.
        """
        
        return prompt
    
    def _summarize_evidence(self, evidence: Evidence) -> str:
        """Create a brief summary of evidence"""
        if evidence.data_type == "metric":
            query = evidence.content.get("query", "Unknown metric")
            anomaly = evidence.content.get("anomaly_detected", False)
            return f"Metric query: {query[:50]}... (Anomaly: {anomaly})"
        elif evidence.data_type == "log":
            message = evidence.content.get("message", "")[:100]
            level = evidence.content.get("level", "INFO")
            return f"Log [{level}]: {message}..."
        else:
            return f"{evidence.data_type.title()} data from {evidence.source}"
    
    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """Parse structured AI response"""
        # Simple parsing - in production, use more sophisticated NLP
        sections = {}
        current_section = None
        
        for line in response.split('\n'):
            line = line.strip()
            if line.endswith(':') and not line.startswith('-'):
                current_section = line[:-1].lower().replace(' ', '_')
                sections[current_section] = []
            elif line.startswith('-') and current_section:
                sections[current_section].append(line[1:].strip())
            elif line and current_section and not line.startswith('-'):
                if current_section not in sections:
                    sections[current_section] = []
                sections[current_section].append(line)
        
        return sections
    
    def _calculate_confidence(self, evidence: List[Evidence]) -> float:
        """Calculate confidence score based on evidence quality"""
        if not evidence:
            return 0.0
        
        # Weight evidence by type and relevance
        weights = {"metric": 0.3, "log": 0.4, "trace": 0.2, "alert": 0.1}
        
        total_score = 0.0
        total_weight = 0.0
        
        for e in evidence:
            weight = weights.get(e.data_type, 0.1)
            total_score += e.relevance_score * weight
            total_weight += weight
        
        return min(total_score / total_weight if total_weight > 0 else 0.0, 1.0)
    
    async def _store_analysis(self, incident: IncidentContext, 
                            evidence: List[Evidence], analysis: str):
        """Store incident analysis for future reference"""
        try:
            document = f"{incident.title} {incident.description} {analysis}"
            
            self.knowledge_base.add(
                documents=[document],
                metadatas=[{
                    "incident_id": incident.incident_id,
                    "title": incident.title,
                    "resolution": analysis,
                    "timestamp": incident.start_time.isoformat(),
                    "severity": incident.severity
                }],
                ids=[f"incident_{incident.incident_id}"]
            )
            
        except Exception as e:
            self.logger.error(f"Error storing analysis: {e}")

class PharosOrchestrator:
    def __init__(self, config: Dict[str, Any]):
        self.data_collector = RAGDataCollector(
            prometheus_url=config['prometheus_url'],
            kibana_url=config['kibana_url'],
            jaeger_url=config['jaeger_url']
        )
        self.ai_analyzer = PharosAIAnalyzer(
            openai_api_key=config['openai_api_key'],
            chroma_db_path=config['chroma_db_path']
        )
        self.slack_client = WebClient(token=config['slack_token'])
        self.logger = logging.getLogger(__name__)
    
    async def process_incident(self, incident_data: Dict[str, Any]) -> Dict[str, Any]:
        """Main orchestration method for incident processing"""
        
        # Parse incident data
        incident = IncidentContext(
            incident_id=incident_data['incident_id'],
            title=incident_data['title'],
            description=incident_data['description'],
            severity=incident_data['severity'],
            start_time=datetime.fromisoformat(incident_data['start_time']),
            affected_services=incident_data.get('affected_services', []),
            symptoms=incident_data.get('symptoms', []),
            customer_reports=incident_data.get('customer_reports', [])
        )
        
        self.logger.info(f"Processing incident {incident.incident_id}")
        
        # Collect evidence from multiple sources
        time_window = timedelta(hours=2)  # Look back 2 hours
        
        metrics_evidence = await self.data_collector.collect_metrics_evidence(
            incident, time_window
        )
        logs_evidence = await self.data_collector.collect_log_evidence(
            incident, time_window
        )
        
        all_evidence = metrics_evidence + logs_evidence
        
        self.logger.info(f"Collected {len(all_evidence)} pieces of evidence")
        
        # Perform AI analysis
        analysis_result = await self.ai_analyzer.analyze_incident(incident, all_evidence)
        
        # Send results to Slack
        await self._send_slack_notification(incident, analysis_result)
        
        return analysis_result
    
    async def _send_slack_notification(self, incident: IncidentContext, 
                                     analysis: Dict[str, Any]):
        """Send analysis results to Slack"""
        try:
            confidence = analysis.get('confidence_score', 0.0)
            root_cause = analysis.get('root_cause_analysis', {})
            
            blocks = [
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": f"🤖 Pharos AI Analysis: {incident.title}"
                    }
                },
                {
                    "type": "section",
                    "fields": [
                        {
                            "type": "mrkdwn",
                            "text": f"*Incident ID:* {incident.incident_id}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*Confidence:* {confidence:.1%}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*Severity:* {incident.severity}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*Evidence Count:* {analysis.get('evidence_count', 0)}"
                        }
                    ]
                }
            ]
            
            # Add root cause if available
            if 'most_likely_root_cause' in root_cause:
                blocks.append({
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*Root Cause:*\n{root_cause['most_likely_root_cause'][0] if root_cause['most_likely_root_cause'] else 'Analysis in progress...'}"
                    }
                })
            
            # Add recommendations
            recommendations = analysis.get('recommended_actions', [])
            if recommendations:
                rec_text = "\n".join([f"• {rec}" for rec in recommendations[:3]])
                blocks.append({
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*Recommended Actions:*\n{rec_text}"
                    }
                })
            
            await self.slack_client.chat_postMessage(
                channel="#incidents",
                blocks=blocks
            )
            
        except Exception as e:
            self.logger.error(f"Error sending Slack notification: {e}")

# Example usage
async def main():
    config = {
        'prometheus_url': 'http://prometheus.monitoring.svc.cluster.local:9090',
        'kibana_url': 'http://kibana.logging.svc.cluster.local:5601',
        'jaeger_url': 'http://jaeger.tracing.svc.cluster.local:16686',
        'openai_api_key': 'sk-...',
        'chroma_db_path': '/data/pharos_knowledge_base',
        'slack_token': 'xoxb-...'
    }
    
    orchestrator = PharosOrchestrator(config)
    
    # Example incident
    incident_data = {
        'incident_id': 'INC-2024-001',
        'title': 'High Error Rate in User Service',
        'description': 'Users reporting login failures and timeouts',
        'severity': 'HIGH',
        'start_time': '2024-01-15T14:30:00Z',
        'affected_services': ['user-service', 'auth-service'],
        'symptoms': ['timeout', 'error 500', 'database connection'],
        'customer_reports': ['Cannot log in', 'Page not loading']
    }
    
    result = await orchestrator.process_incident(incident_data)
    print(json.dumps(result, indent=2))

if __name__ == "__main__":
    asyncio.run(main())</code></pre>
                </div>
                
                <h4 class="text-lg font-semibold text-gray-800 mb-2">Telegraf Plugin for Custom Metrics Collection</h4>
                <div class="bg-gray-900 text-green-400 p-4 rounded-lg mb-4 text-sm font-mono overflow-x-auto">
                    <pre><code># Custom Telegraf input plugin for application-specific metrics
[[inputs.exec]]
  commands = ["/usr/local/bin/collect_app_metrics.py"]
  timeout = "30s"
  data_format = "influx"
  interval = "10s"

[[inputs.prometheus]]
  urls = ["http://app-service:9090/metrics"]
  metric_version = 2
  interval = "15s"

[[inputs.http_listener_v2]]
  service_address = ":8186"
  path = "/telegraf"
  methods = ["POST"]
  data_format = "json"

# Custom metric collection script
#!/usr/bin/env python3

import json
import time
import psutil
import requests
from datetime import datetime

def collect_application_metrics():
    """Collect custom application metrics"""
    
    # Database connection pool metrics
    db_metrics = get_database_metrics()
    
    # Cache hit/miss ratios
    cache_metrics = get_cache_metrics()
    
    # Custom business metrics
    business_metrics = get_business_metrics()
    
    # System performance metrics
    system_metrics = get_system_metrics()
    
    # Format as InfluxDB line protocol
    timestamp = int(time.time() * 1000000000)  # nanoseconds
    
    metrics = []
    
    # Database metrics
    for db_name, stats in db_metrics.items():
        metrics.append(
            f"database_connections,database={db_name} "
            f"active={stats['active']},idle={stats['idle']},max_conn={stats['max_connections']} "
            f"{timestamp}"
        )
    
    # Cache metrics
    for cache_name, stats in cache_metrics.items():
        hit_rate = stats['hits'] / (stats['hits'] + stats['misses']) if (stats['hits'] + stats['misses']) > 0 else 0
        metrics.append(
            f"cache_performance,cache={cache_name} "
            f"hit_rate={hit_rate},hits={stats['hits']},misses={stats['misses']},size={stats['size']} "
            f"{timestamp}"
        )
    
    # Business metrics
    metrics.append(
        f"business_metrics "
        f"active_users={business_metrics['active_users']},"
        f"successful_transactions={business_metrics['successful_transactions']},"
        f"failed_transactions={business_metrics['failed_transactions']},"
        f"revenue_per_minute={business_metrics['revenue_per_minute']} "
        f"{timestamp}"
    )
    
    # System metrics
    metrics.append(
        f"system_performance "
        f"cpu_percent={system_metrics['cpu_percent']},"
        f"memory_percent={system_metrics['memory_percent']},"
        f"disk_io_read={system_metrics['disk_io_read']},"
        f"disk_io_write={system_metrics['disk_io_write']},"
        f"network_bytes_sent={system_metrics['network_bytes_sent']},"
        f"network_bytes_recv={system_metrics['network_bytes_recv']} "
        f"{timestamp}"
    )
    
    return "\n".join(metrics)

def get_database_metrics():
    """Collect database connection pool metrics"""
    try:
        # Example: PostgreSQL connection pool metrics
        response = requests.get("http://localhost:8080/admin/database/stats", timeout=5)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    
    # Fallback metrics
    return {
        "primary": {"active": 5, "idle": 15, "max_connections": 20},
        "readonly": {"active": 3, "idle": 7, "max_connections": 10}
    }

def get_cache_metrics():
    """Collect cache performance metrics"""
    try:
        # Example: Redis cache metrics
        response = requests.get("http://localhost:8080/admin/cache/stats", timeout=5)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    
    # Fallback metrics
    return {
        "redis_main": {"hits": 1500, "misses": 100, "size": 1024000},
        "memcached": {"hits": 800, "misses": 50, "size": 512000}
    }

def get_business_metrics():
    """Collect business-specific metrics"""
    try:
        # Query application database for business metrics
        response = requests.get("http://localhost:8080/admin/business/metrics", timeout=5)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    
    # Fallback metrics
    return {
        "active_users": 150,
        "successful_transactions": 45,
        "failed_transactions": 2,
        "revenue_per_minute": 125.50
    }

def get_system_metrics():
    """Collect system performance metrics"""
    return {
        "cpu_percent": psutil.cpu_percent(interval=1),
        "memory_percent": psutil.virtual_memory().percent,
        "disk_io_read": psutil.disk_io_counters().read_bytes if psutil.disk_io_counters() else 0,
        "disk_io_write": psutil.disk_io_counters().write_bytes if psutil.disk_io_counters() else 0,
        "network_bytes_sent": psutil.net_io_counters().bytes_sent,
        "network_bytes_recv": psutil.net_io_counters().bytes_recv
    }

if __name__ == "__main__":
    metrics = collect_application_metrics()
    print(metrics)</code></pre>
                </div>
                
                <h4 class="text-lg font-semibold text-gray-800 mb-2">Kubernetes CRD for SLI/SLO Management</h4>
                <div class="bg-gray-900 text-green-400 p-4 rounded-lg mb-4 text-sm font-mono overflow-x-auto">
                    <pre><code># Custom Resource Definition for automated SLI/SLO generation
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: servicelevels.monitoring.thoughtspot.com
spec:
  group: monitoring.thoughtspot.com
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              serviceName:
                type: string
                description: "Name of the service to monitor"
              environment:
                type: string
                enum: ["development", "staging", "production"]
              slis:
                type: array
                items:
                  type: object
                  properties:
                    name:
                      type: string
                    type:
                      type: string
                      enum: ["availability", "latency", "throughput", "error_rate"]
                    query:
                      type: string
                      description: "Prometheus query for the SLI"
                    threshold:
                      type: number
                      description: "SLO threshold value"
                    window:
                      type: string
                      description: "Time window for SLO evaluation"
              alerting:
                type: object
                properties:
                  enabled:
                    type: boolean
                    default: true
                  channels:
                    type: array
                    items:
                      type: string
                  escalation:
                    type: object
                    properties:
                      enabled:
                        type: boolean
                      levels:
                        type: array
                        items:
                          type: object
                          properties:
                            threshold:
                              type: number
                            action:
                              type: string
          status:
            type: object
            properties:
              phase:
                type: string
              lastUpdated:
                type: string
              generatedResources:
                type: array
                items:
                  type: object
                  properties:
                    kind:
                      type: string
                    name:
                      type: string
                    namespace:
                      type: string
  scope: Namespaced
  names:
    plural: servicelevels
    singular: servicelevel
    kind: ServiceLevel
    shortNames:
    - slo

---
# Example ServiceLevel custom resource
apiVersion: monitoring.thoughtspot.com/v1
kind: ServiceLevel
metadata:
  name: user-service-slo
  namespace: production
spec:
  serviceName: user-service
  environment: production
  
  slis:
  - name: availability
    type: availability
    query: 'up{service="user-service"}'
    threshold: 0.999
    window: 30d
    
  - name: response_time_p95
    type: latency
    query: 'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{service="user-service"}[5m]))'
    threshold: 0.5
    window: 30d
    
  - name: error_rate
    type: error_rate
    query: 'rate(http_requests_total{service="user-service",status=~"5.."}[5m]) / rate(http_requests_total{service="user-service"}[5m])'
    threshold: 0.001
    window: 30d
    
  - name: throughput
    type: throughput
    query: 'rate(http_requests_total{service="user-service"}[5m])'
    threshold: 100
    window: 30d
  
  alerting:
    enabled: true
    channels:
      - "#sre-alerts"
      - "#user-service-team"
    escalation:
      enabled: true
      levels:
      - threshold: 0.1
        action: "notify_team"
      - threshold: 0.05
        action: "page_oncall"
      - threshold: 0.01
        action: "escalate_management"

---
# Kubernetes controller for ServiceLevel CRD (Go implementation outline)
# This would be implemented as a full Go controller using controller-runtime

package main

import (
    "context"
    "fmt"
    
    "sigs.k8s.io/controller-runtime/pkg/client"
    "sigs.k8s.io/controller-runtime/pkg/controller"
    "sigs.k8s.io/controller-runtime/pkg/handler"
    "sigs.k8s.io/controller-runtime/pkg/reconcile"
    "sigs.k8s.io/controller-runtime/pkg/source"
    
    monitoringv1 "github.com/thoughtspot/monitoring-operator/api/v1"
    prometheusv1 "github.com/prometheus-operator/prometheus-operator/pkg/apis/monitoring/v1"
)

type ServiceLevelReconciler struct {
    client.Client
    Scheme *runtime.Scheme
}

func (r *ServiceLevelReconciler) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) {
    // Fetch the ServiceLevel instance
    var serviceLevel monitoringv1.ServiceLevel
    if err := r.Get(ctx, req.NamespacedName, &serviceLevel); err != nil {
        return reconcile.Result{}, client.IgnoreNotFound(err)
    }
    
    // Generate Prometheus rules for SLIs
    prometheusRule := r.generatePrometheusRules(&serviceLevel)
    if err := r.createOrUpdatePrometheusRule(ctx, prometheusRule); err != nil {
        return reconcile.Result{}, err
    }
    
    // Generate alerting rules
    alertingRules := r.generateAlertingRules(&serviceLevel)
    if err := r.createOrUpdateAlertingRules(ctx, alertingRules); err != nil {
        return reconcile.Result{}, err
    }
    
    // Generate Grafana dashboard
    dashboard := r.generateGrafanaDashboard(&serviceLevel)
    if err := r.createOrUpdateDashboard(ctx, dashboard); err != nil {
        return reconcile.Result{}, err
    }
    
    // Update status
    serviceLevel.Status.Phase = "Ready"
    serviceLevel.Status.LastUpdated = time.Now().Format(time.RFC3339)
    
    return reconcile.Result{}, r.Status().Update(ctx, &serviceLevel)
}

func (r *ServiceLevelReconciler) generatePrometheusRules(sl *monitoringv1.ServiceLevel) *prometheusv1.PrometheusRule {
    rules := []prometheusv1.Rule{}
    
    for _, sli := range sl.Spec.SLIs {
        // Generate recording rule for SLI
        rules = append(rules, prometheusv1.Rule{
            Record: fmt.Sprintf("sli:%s:%s", sl.Spec.ServiceName, sli.Name),
            Expr:   intstr.FromString(sli.Query),
            Labels: map[string]string{
                "service":     sl.Spec.ServiceName,
                "environment": sl.Spec.Environment,
                "sli_type":    sli.Type,
            },
        })
        
        // Generate SLO compliance rule
        sloQuery := fmt.Sprintf(
            "avg_over_time(sli:%s:%s[%s]) > %f",
            sl.Spec.ServiceName,
            sli.Name,
            sli.Window,
            sli.Threshold,
        )
        
        rules = append(rules, prometheusv1.Rule{
            Record: fmt.Sprintf("slo:%s:%s:compliance", sl.Spec.ServiceName, sli.Name),
            Expr:   intstr.FromString(sloQuery),
            Labels: map[string]string{
                "service":     sl.Spec.ServiceName,
                "environment": sl.Spec.Environment,
                "slo_name":    sli.Name,
                "threshold":   fmt.Sprintf("%.3f", sli.Threshold),
            },
        })
    }
    
    return &prometheusv1.PrometheusRule{
        ObjectMeta: metav1.ObjectMeta{
            Name:      fmt.Sprintf("%s-slo-rules", sl.Spec.ServiceName),
            Namespace: sl.Namespace,
            Labels: map[string]string{
                "app":                sl.Spec.ServiceName,
                "monitoring.thoughtspot.com/slo": "true",
            },
        },
        Spec: prometheusv1.PrometheusRuleSpec{
            Groups: []prometheusv1.RuleGroup{
                {
                    Name:  fmt.Sprintf("%s.slo.rules", sl.Spec.ServiceName),
                    Rules: rules,
                },
            },
        },
    }
}</code></pre>
                </div>
                
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mt-4">
                    <div class="bg-blue-50 p-4 rounded-lg">
                        <h5 class="font-semibold text-blue-800 mb-2">
                            <i class="fab fa-github mr-2"></i>Repository Links
                        </h5>
                        <ul class="text-blue-700 text-sm space-y-1">
                            <li><a href="#" class="hover:underline">→ Pharos AI RCA System</a></li>
                            <li><a href="#" class="hover:underline">→ Custom Telegraf Plugins</a></li>
                            <li><a href="#" class="hover:underline">→ Kubernetes SLO Operator</a></li>
                            <li><a href="#" class="hover:underline">→ Observability Dashboards</a></li>
                        </ul>
                    </div>
                    
                    <div class="bg-green-50 p-4 rounded-lg">
                        <h5 class="font-semibold text-green-800 mb-2">
                            <i class="fas fa-file-code mr-2"></i>Technical Documentation
                        </h5>
                        <ul class="text-green-700 text-sm space-y-1">
                            <li><a href="#" class="hover:underline">→ AI-Powered RCA Architecture</a></li>
                            <li><a href="#" class="hover:underline">→ CFD Reduction Strategies</a></li>
                            <li><a href="#" class="hover:underline">→ Proactive Monitoring Playbook</a></li>
                            <li><a href="#" class="hover:underline">→ Cost Optimization Techniques</a></li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="detail-section">
                <h3>Development Practices & Quality Assurance</h3>
                
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                        <h4 class="text-lg font-semibold text-gray-800 mb-3">
                            <i class="fas fa-vial mr-2 text-purple-600"></i>AI System Testing Strategy
                        </h4>
                        <div class="space-y-3">
                            <div class="bg-purple-50 p-3 rounded">
                                <h5 class="font-medium text-purple-800">ML/AI Testing</h5>
                                <ul class="text-purple-700 text-sm mt-1 space-y-1">
                                    <li>• RAG system accuracy and retrieval testing</li>
                                    <li>• AI model performance and bias validation</li>
                                    <li>• Knowledge base embedding quality assessment</li>
                                </ul>
                            </div>
                            
                            <div class="bg-purple-50 p-3 rounded">
                                <h5 class="font-medium text-purple-800">Observability Testing</h5>
                                <ul class="text-purple-700 text-sm mt-1 space-y-1">
                                    <li>• SLI/SLO automation and accuracy testing</li>
                                    <li>• Dashboard functionality and data integrity</li>
                                    <li>• Alert fatigue reduction validation</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div>
                        <h4 class="text-lg font-semibold text-gray-800 mb-3">
                            <i class="fab fa-git-alt mr-2 text-orange-600"></i>Proactive Operations
                        </h4>
                        <div class="space-y-3">
                            <div class="bg-orange-50 p-3 rounded">
                                <h5 class="font-medium text-orange-800">AI-Powered Automation</h5>
                                <ul class="text-orange-700 text-sm mt-1 space-y-1">
                                    <li>• Automated root cause analysis deployment</li>
                                    <li>• Real-time incident correlation and triage</li>
                                    <li>• Knowledge base continuous learning</li>
                                </ul>
                            </div>
                            
                            <div class="bg-orange-50 p-3 rounded">
                                <h5 class="font-medium text-orange-800">Operational Excellence</h5>
                                <ul class="text-orange-700 text-sm mt-1 space-y-1">
                                    <li>• Proactive bug hunting and detection</li>
                                    <li>• Cost optimization feedback loops</li>
                                    <li>• Cross-team collaboration and training</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="mt-6 bg-gray-50 p-4 rounded-lg">
                    <h4 class="text-lg font-semibold text-gray-800 mb-2">
                        <i class="fas fa-shield-alt mr-2 text-green-600"></i>Observability Enhancement Metrics
                    </h4>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mt-3">
                        <div class="text-center">
                            <div class="text-2xl font-bold text-blue-600">40%</div>
                            <div class="text-sm text-gray-600">CFD Reduction</div>
                        </div>
                        <div class="text-center">
                            <div class="text-2xl font-bold text-green-600">30%</div>
                            <div class="text-sm text-gray-600">Faster Incident Resolution</div>
                        </div>
                        <div class="text-center">
                            <div class="text-2xl font-bold text-purple-600">38%</div>
                            <div class="text-sm text-gray-600">Logging Cost Reduction</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mt-8 flex justify-center space-x-4">
                <a href="projects.html" class="btn-primary flex items-center space-x-2">
                    <i class="fas fa-arrow-left"></i> <span>Back to All Projects</span>
                </a>
                <a href="index.html" class="btn-primary flex items-center space-x-2">
                    <i class="fas fa-home"></i> <span>Back to Home</span>
                </a>
            </div>

        <!-- Project Navigation Section -->
